{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv\n",
    "\n",
    "1. Load the CSV file using pandas.\n",
    "2. Use the apply function to obtain the WAV file path.\n",
    "3. Perform the above steps for the training data, public data, and private data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "source_df = pd.read_csv(r'..\\Training_Dataset\\training_datalist.csv')\n",
    "source_df['wave_path'] = source_df['ID'].apply(lambda x:f'..\\\\Training_Dataset\\\\training_voice_data\\\\{x}.wav')\n",
    "source_df\n",
    "\n",
    "# Public Data\n",
    "public_df = pd.read_csv(r'..\\Public_Testing_Dataset\\test_datalist_public.csv')\n",
    "public_df['wave_path'] = public_df['ID'].apply(lambda x: f'..\\\\Public_Testing_Dataset\\\\test_data_public\\\\{x}.wav')\n",
    "public_df\n",
    "\n",
    "# Private Data\n",
    "private_df = pd.read_csv(r'..\\Private_Testing_Dataset\\test_datalist_private.csv')\n",
    "private_df['wave_path'] = private_df['ID'].apply(lambda x: f'..\\\\Private_Testing_Dataset\\\\test_data_private\\\\{x}.wav')\n",
    "private_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make MFCC function\n",
    "1. Load the .wav file.\n",
    "2. Cut the file into one-second segments (`signal = signal_tem[:44100]`).\n",
    "3. Utilize the `mfcc` function from the `librosa` library to extract the MFCC (Mel-frequency cepstral coefficients) data.\n",
    "4. Save the MFCC data to a .npy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mfcc(df:pd.DataFrame, n_mfcc=13):\n",
    "    for file_path in df['wave_path'].to_list():\n",
    "\n",
    "        signal_tem, sample_rate = librosa.load(file_path, sr=44100)\n",
    "        signal = signal_tem[:44100]        \n",
    "\n",
    "        n_fft = int(16/1000 * sample_rate)  \n",
    "        hop_length = int(8/1000 * sample_rate)\n",
    "\n",
    "        # MFCCs\n",
    "        MFCCs = librosa.feature.mfcc(y=signal, sr =sample_rate, n_fft=n_fft, hop_length=hop_length, n_mfcc=n_mfcc)\n",
    "        # print(MFCCs.shape)\n",
    "\n",
    "        np.save(file_path.replace('.wav', f'_mfcc_{n_mfcc}.npy'), MFCCs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmfcc_list = [13, 17, 21, 30, 50]\n",
    "\n",
    "for number in nmfcc_list:\n",
    "    make_mfcc(source_df, n_mfcc=number)\n",
    "    make_mfcc(public_df, n_mfcc=number)\n",
    "    make_mfcc(private_df, n_mfcc=number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
