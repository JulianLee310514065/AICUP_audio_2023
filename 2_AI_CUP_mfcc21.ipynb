{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Import library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnC7wEOl-Bt7"},"outputs":[],"source":["# origin library\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import SGD\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, transforms\n","\n","import librosa\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, recall_score\n","from sklearn.model_selection import StratifiedKFold\n","\n","\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Function define"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 官方提供之前處理函數\n","def medical_data_proccessing(df):\n","    # 將性別編碼0,1\n","    df['Sex'] = df['Sex'] - 1\n","\n","    # 將空值填0\n","    df['PPD'] = df['PPD'].fillna(0)\n","    df['Voice handicap index - 10'] = df['Voice handicap index - 10'].fillna(0)\n","\n","    # 正規化過大的數值\n","    df['Age'] = df['Age'] / 50\n","    df['Voice handicap index - 10'] = df['Voice handicap index - 10'] / 40\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def standardization(data):\n","    mu = np.mean(data, axis=0)\n","    sigma = np.std(data, axis=0)\n","    return (data - mu) / sigma"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# training dataset\n","class CustomImageDataset(Dataset):\n","    def __init__(self, source_df, transform=None, target_transform=None):\n","\n","        self.dataframe = source_df\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","        self.medical = self.dataframe.drop(columns= ['ID', 'mfcc_path', 'Disease category'])\n","        self.path = self.dataframe['mfcc_path']\n","        self.label_df = self.dataframe['Disease category']\n","        \n","\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","\n","        img_path = self.path.iloc[idx]\n","        \n","        mfcc_img = np.load(img_path)\n","        mfcc_img = standardization(mfcc_img)\n","\n","        medicals = self.medical.iloc[idx].values\n","\n","        label = self.label_df.iloc[idx]\n","\n","        if self.transform:\n","            mfcc_img = self.transform(mfcc_img)\n","\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        \n","        # return medicals \n","        return mfcc_img, medicals, label, img_path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# public and private dataset\n","class CustomImageDataset_public(Dataset):\n","    def __init__(self, source_df, transform=None, target_transform=None):\n","        \n","        self.dataframe = source_df\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","        self.medical = self.dataframe.drop(columns= ['ID', 'mfcc_path'])\n","        self.path = self.dataframe['mfcc_path']\n","        self.id = self.dataframe['ID']\n","    \n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","                \n","        img_path = self.path.iloc[idx]\n","        \n","        mfcc_img = np.load(img_path)\n","        mfcc_img = standardization(mfcc_img)\n","\n","        medicals = self.medical.iloc[idx].values                \n","\n","        ids = self.id.iloc[idx]            \n","\n","        if self.transform:\n","            mfcc_img = self.transform(mfcc_img)\n","\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        \n","        # return medicals \n","        return mfcc_img, medicals, ids"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# set torch device\n","device = torch.device('cuda:0')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Network(nn.Module):\n","    def __init__(self, pool = 1, fc1=128, maxpool=2):\n","        super(Network, self).__init__()\n","        # CNN - MFCC圖片\n","        self.maxpool = maxpool\n","\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm2d(16)        \n","        self.pool1 = nn.MaxPool2d(self.maxpool, padding= 1)\n","        \n","        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 10), stride=1, padding=1)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.pool2 = nn.MaxPool2d(self.maxpool, padding= 1)\n","        \n","        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 10), stride=1, padding=1)\n","        self.bn3 = nn.BatchNorm2d(64)\n","        self.pool3 = nn.MaxPool2d(self.maxpool, padding= 1)\n","\n","        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n","        self.bn4 = nn.BatchNorm2d(64)   \n","        self.pool4 = nn.MaxPool2d(self.maxpool, padding= 1)\n","\n","        self.conv5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n","        self.bn5 = nn.BatchNorm2d(64)\n","\n","        self.conv6 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n","        self.bn6 = nn.BatchNorm2d(64)\n","\n","        self.conv7 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n","        self.bn7 = nn.BatchNorm2d(128)\n","        \n","        # Avg pool \n","        self.pools = pool        \n","        self.ave_pool = nn.AdaptiveAvgPool2d(self.pools)\n","\n","\n","        # MLP - 生理資訊\n","        self.linear1= nn.Linear(44, 1024)\n","        self.l1 = nn.BatchNorm1d(1024)\n","        # self.dropmlp = nn.Dropout(0.1)\n","        self.linear2= nn.Linear(1024, 256) \n","        self.l2 = nn.BatchNorm1d(256)\n","        self.linear3= nn.Linear(256, 128)\n","        \n","        # FC - 分類用\n","        self.fc1_num = fc1\n","        self.fc1 = nn.Linear(64*self.pools*self.pools + 128, self.fc1_num)\n","        self.bnfc = nn.BatchNorm1d(self.fc1_num)\n","        self.fc2 = nn.Linear(self.fc1_num, 5)\n","        self.soft = nn.Softmax(dim=1)\n","        self.drop = nn.Dropout(0.3)\n","\n","\n","    def forward(self, input1, medical_in):\n","        # cnn\n","        output = F.celu(self.conv1(input1))\n","        output = self.bn1(output)\n","        output = self.pool1(output) \n","\n","        output = F.celu(self.conv2(output))     \n","        output = self.bn2(output)\n","        output = self.pool2(output)\n","\n","        output = F.celu(self.conv3(output)) \n","        output = self.bn3(output)\n","        output = self.pool3(output)   \n","\n","        output = self.ave_pool(output)\n","        output = output.view(-1, 64*self.pools*self.pools)\n","\n","        # medical data\n","        x = F.celu(self.linear1(medical_in))\n","        x = F.celu(self.linear2(x))\n","        x = F.celu(self.linear3(x))\n","        \n","        # concat\n","        con = torch.cat((output, x), 1)    \n","        con = F.celu(self.fc1(con))\n","        # con  = self.drop(con)\n","        con = self.bnfc(con)\n","        con = self.fc2(con)           \n","        con = self.soft(con)\n","\n","        return con"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# read csv data\n","source_df = pd.read_csv(r'..\\Training_Dataset\\training_datalist.csv')\n","source_df['mfcc_path'] = source_df['ID'].apply(lambda x:f'..\\\\Training_Dataset\\\\training_voice_data\\\\{x}_mfcc_21.npy')\n","\n","# data preprocessing\n","source_df_pro = medical_data_proccessing(source_df)\n","source_df_pro = pd.get_dummies(source_df_pro, columns=['Smoking', 'frequency', 'Onset of dysphonia ', 'Noise at work', 'Diurnal pattern', 'Occupational vocal demand'])\n","source_df_pro['Disease category'] = source_df_pro['Disease category'] - 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# StratifiedKFold\n","skf = StratifiedKFold(n_splits=4, shuffle=True)\n","fold1 = list(skf.split(source_df_pro, source_df_pro['Disease category']))[0]\n","\n","training_df = source_df_pro.loc[fold1[0]]\n","test_df = source_df_pro.loc[fold1[1]]\n","print(\"training_df shape :\", training_df.shape, \", test_df shape :\", test_df.shape)\n","\n","# 計算每一類的數量，讓CrossEntropyLoss做使用\n","numberlist = training_df['Disease category'].value_counts().sort_index().to_list()\n","print(training_df['Disease category'].value_counts().sort_index())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# dataset and dataloader\n","trans_comp = transforms.Compose([transforms.ToTensor()])\n","train_dataset = CustomImageDataset(training_df, transform= trans_comp)\n","test_dataset = CustomImageDataset(test_df, transform= trans_comp)\n","train_dl = DataLoader(train_dataset, batch_size= 32, shuffle= True, drop_last=True)\n","test_dl = DataLoader(test_dataset, batch_size= 32, shuffle= False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model \n","model = Network().to(device)\n","\n","# optimizer\n","weight = torch.tensor([1/numberlist[0], 1/numberlist[1], 1/numberlist[2], 1/numberlist[3], 1/numberlist[4]]).to(device)\n","criterion = nn.CrossEntropyLoss(weight=weight)\n","optimizer = SGD(model.parameters(), lr=0.01, weight_decay= 0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train\n","train_acc_list = [0]\n","test_acc_list = [0]\n","before_acc = 0.\n","\n","# epoch\n","epoch = 150\n","\n","for epoch in range(epoch):\n","    predict_save = []\n","    label_save = []\n","    losses = 0.  \n","    \n","    # training dataset\n","    for batch, (mfcc_img, medicals, label, img_path) in enumerate(train_dl):\n","        model.train()\n","        \n","        inputs, medicals, labels = mfcc_img.float().to(device), medicals.float().to(device), label.to(device)\n","        optimizer.zero_grad()\n","        pred_out = model(inputs, medicals)\n","        \n","        loss = criterion(pred_out, labels)\n","        losses = losses + loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        digital = list(pred_out.cpu().argmax(1))\n","        train_label = list(label.cpu())\n","        \n","        predict_save += digital\n","        label_save += train_label\n","\n","    y_pred = [x.item() for x in predict_save]\n","    y_true = [cc.item() for cc in label_save]\n","\n","    results_recall = recall_score(y_true, y_pred, average=None)\n","    train_mean = results_recall.mean()\n","    train_acc_list.append(train_mean)\n","    # print(\"Training UAR(Unweighted Average Recall) :\", train_mean)\n","\n","    # validation dataset\n","    pre_save_test = []\n","    label_save_test = []\n","    model.eval()\n","    with torch.no_grad():\n","        for mfcc_img, medicals, label, img_path in test_dl:\n","            inputs, medicals, labels = mfcc_img.float().to(device), medicals.float().to(device), label.to(device)\n","\n","            pred = model(inputs, medicals)\n","            \n","            digital = list(pred.cpu().argmax(1))\n","            lab = list(labels.cpu())\n","            \n","            pre_save_test += digital\n","            label_save_test += lab\n","\n","    y_predt = [x.item() for x in pre_save_test]\n","    y_truet = [cc.item() for cc in label_save_test]\n","\n","    results_recallt = recall_score(y_truet, y_predt, average=None)\n","    test_mean = results_recallt.mean()\n","    test_acc_list.append(test_mean)\n","    # print(\"Test UAR(Unweighted Average Recall) :\", test_mean)\n","\n","    # 存model\n","    if test_mean > before_acc:\n","        before_acc = test_mean\n","        torch.save(model.state_dict(), \"{}.pth\".format(\"mfcc21_use_all\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 畫出結果圖\n","plt.figure(figsize= (10,5))\n","plt.plot(np.arange(len(train_acc_list)), train_acc_list, label= 'Train_recall')\n","plt.plot(np.arange(len(test_acc_list)), test_acc_list, label= 'Test_recall')\n","plt.legend(fontsize= 15)\n","plt.xlabel('Epochs')\n","plt.ylabel('Mean Recall')\n","plt.title('Recall Plot', fontsize= 15)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Load Best Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.load_state_dict(torch.load(\"{}.pth\".format(\"mfcc21_use_all\")))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pre_save_test = []\n","label_save_test = []\n","model.eval()\n","with torch.no_grad():\n","    for mfcc_img, medicals, label, img_path in test_dl:\n","        inputs, medicals, labels = mfcc_img.float().to(device), medicals.float().to(device), label.to(device)\n","\n","        pred = model(inputs, medicals)\n","        \n","        digital = list(pred.cpu().argmax(1))\n","        lab = list(labels.cpu())\n","        \n","        pre_save_test += digital\n","        label_save_test += lab\n","\n","y_predt = [x.item() for x in pre_save_test]\n","y_truet = [cc.item() for cc in label_save_test]\n","\n","results_recallt = recall_score(y_truet, y_predt, average=None)\n","test_mean = results_recallt.mean()\n","print(\"Test UAR(Unweighted Average Recall) :\", test_mean)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_recall = recall_score(y_truet, y_predt, average=None)\n","print(\"Training UAR(Unweighted Average Recall) :\", results_recall.mean())\n","cm = confusion_matrix(y_truet, y_predt)\n","ConfusionMatrixDisplay(confusion_matrix(y_truet, y_predt)).plot(cmap='Blues')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Predict - public data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load public csv\n","data_df = pd.read_csv(r'..\\Public_Testing_Dataset\\test_datalist_public.csv')\n","data_df['mfcc_path'] = data_df['ID'].apply(lambda x: f'..\\\\Public_Testing_Dataset\\\\test_data_public\\\\{x}_mfcc_21.npy')\n","\n","# preprocessing of public csv\n","data_df_pro = medical_data_proccessing(data_df)\n","data_df_pro = pd.get_dummies(data_df_pro, columns=['Smoking', 'frequency', 'Onset of dysphonia ', 'Noise at work', 'Diurnal pattern', 'Occupational vocal demand'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trans_comp = transforms.Compose([transforms.ToTensor()])\n","pub_dataset = CustomImageDataset_public(data_df_pro, transform= trans_comp)\n","pub_dl = DataLoader(pub_dataset, batch_size= 32, shuffle= False)\n","print(pub_dataset.__len__())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pub_save = []\n","id_list = []\n","model.eval()\n","with torch.no_grad():\n","    for mfcc_img, medicals, img_path in pub_dl:\n","        inputs, medicals= mfcc_img.float().to(device), medicals.float().to(device)\n","        # print(inputs.shape)\n","        pred = model(inputs, medicals)\n","        \n","        digital = list(pred.cpu())\n","           \n","        pub_save += digital\n","        id_list += img_path\n","   \n","\n","y_pub = [x.numpy() for x in pub_save]\n","y_pub[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Predict - private data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load private data\n","data_private_df = pd.read_csv(r'..\\Private_Testing_Dataset\\test_datalist_private.csv')\n","data_private_df['mfcc_path'] = data_private_df['ID'].apply(lambda x: f'..\\\\Private_Testing_Dataset\\\\test_data_private\\\\{x}_mfcc_21.npy')\n","\n","# preprocessing of private data\n","data_private_pro = medical_data_proccessing(data_private_df)\n","data_private_pro = pd.get_dummies(data_private_pro, columns=['Smoking', 'frequency', 'Onset of dysphonia ', 'Noise at work', 'Diurnal pattern', 'Occupational vocal demand'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trans_comp = transforms.Compose([transforms.ToTensor()])\n","pri_dataset = CustomImageDataset_public(data_private_pro, transform= trans_comp)\n","pri_dl = DataLoader(pri_dataset, batch_size= 32, shuffle= False)\n","print(pri_dataset.__len__())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pub_save_private = []\n","id_list_private = []\n","model.eval()\n","with torch.no_grad():\n","    for mfcc_img, medicals, img_path in pri_dl:\n","        inputs, medicals= mfcc_img.float().to(device), medicals.float().to(device)\n","        # print(inputs.shape)\n","        pred = model(inputs, medicals)\n","        \n","        digital = list(pred.cpu())\n","           \n","        pub_save_private += digital\n","        id_list_private += img_path\n","   \n","\n","y_pri = [x.numpy() for x in pub_save_private]\n","y_pri[:5]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Combine"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_all = y_pub + y_pri\n","print(len(y_all))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mmffcc21 = np.array(y_all)\n","np.save('output_mfcc21.npy', mmffcc21)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"modelenv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f97432c16914304dbd818b138841742b9483a5a148ca981647dc7438178b3282"}}},"nbformat":4,"nbformat_minor":0}
